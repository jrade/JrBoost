new GitHub login method
	https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/

========================================================================================================================

separate outer and inner thread counts

	thread local data:

		// written by outer threads only (no synch)
		inline static thread_local RandomNumberEngine_ tlRne_;

		// written by outer threads and read by inner threads (synch at beginning of block)
		inline static thread_local vector<size_t> tlUsedVariables_;
		inline static thread_local vector<SampleIndex> tlSampleStatus_;
		inline static thread_local vector<vector<TreeNode>> tlTree_;
		inline static thread_local vector<size_t> tlSampleCountByParentNode_;
		inline static thread_local vector<size_t> tlSampleCountByChildNode_;

		// written by outer threads and written by inner threads (synch at beginning and end of block)
		inline static thread_local vector<Split> tlSplits_;

		// written by inner threads only (no synch)
		inline static thread_local vector<vector<SampleIndex>> tlOrderedSamplesByVariable_;
		inline static thread_local vector<typename std::span<SampleIndex>::iterator> tlOrderedSampleIndex_;

		// written both outer threads and separately (no data sharing) by inner threads (no synch)
		inline static thread_local vector<SampleIndex> tlSampleBuffer_;

	one possible design:
		replace thread local static by static vectors indexed by thread id?
			how do we manage their sizes?
			keep track of both outer and inner thread id

	another possible design:
		separate otl and itl members
		have the shared as both otl and itl and do a handover at the beginning and end of the inner parallel region
		easier to implement based on current code


Profiling cases (both on notebook and stationary PC)
	Leukemia build-and-validate
	higgs.py and higgs_quick.py

TreeBuilderImpl:

	clean up the init/update ordered samples functions

	profile the two implementations
		compare the detaled profile logs
		is the alt implementation faster?

		profiling cases:
			TCGA500 validiate (12h on desktop)
			higgs (?? on desktop)

	continue cleaning up the initOrderedSamples functions

	other implementations:
		resurrect filtered ordered samples implementation (filter once or for each level?)
			could in fact be the best implementation

	notes:
		the alt implementation can not be used with variables per level
		the alt implementtaion should not be used with depth 1 (would waste a lot of memory)

classifier compactification

Minor things:
	test pruning again (also with abs limit)
	Trick to reduce rounding off errors towards the end
		calculate right sums as total - left instead of doing it incrementally
		then we should have right right sum == 0.0 at the end (assert this?)
	are static thread_local buffers worth the trouble? some of them? profile
	if we allowed depth = 0 (and why wouldn't we?), then root would not get properly initialized
	let split class find the splits??
		can also update the tree - see the TreeBuilderAlt / NodeBuilder code

------------------------------------------------------------------------------------------------------------------------

Higgs:

	feature engineerings
		read paper appendix A, then appendix B
		look at winning (and other) submissions

	target loss functions (for fitting hyper parameters):
		AUC:      3.7372 -> 3.7403
		AMS:      3.7340 -> 3.7342
		ll(1e-3): 3.7156 -> 3.7073
	
	more robust AMS cutoff fitting (testing every possible cutoff may lead to overfitting, apply some smoothing?)
	also: test simple cutoff again
	population optimization parameters (generator approach)
	repetition count

	minGain feature
	forward and backward pruning
	drop useless variables?

	cross-validation for fitting hyper parameters and AMS cutoff
		only use the data files train.csv and test.csv from Kaggle competition
		trainer that works with sample subset

	look at final version of my Kaggle code
	look at winning submissions, paper, code at https://github.com/melisgl/higgsml
	look at other publicly available submissions
		
	do some profiling
		how does it scale with number of cores (using the full dataset)
		what takes so much time at the end?

	compare with the xgbost higgs example:
		speed, accuracy?

	how does higgs.py find jrboost when importing it? (this ís a bit of a mystery)

------------------------------------------------------------------------------------------------------------------------

major tasks:
	improved Otto example
	gradient boost (Friedman and xgb papers)
		first and second order boost with any gamma
	BART
	histogram-based tree builder (would speed up Otto a lot)
	multinomial predictors

features to add:
	classifier compactification (remove unused variables, renumber (and reorder) the remaining variables)
	tree regularization: L2 penalty (lambda), L1 penalty (alpha)
	used variable subset by level option (may be expensive)
	predict overload that takes a one-dim array and returns a double (use in QD Demo)
	multiple inData and multiple variable counts (to handle feature engineering etc.)
	set seed (to make the training process deterministic)
	U-test (with correct handling of ties)

minor things:
	Rename the jrboost.py project Python, move it up one step in the solution explorer hierarchy
	decrease default gamma (in log loss) from 0.1 to 0.001?
	Predictor::_predict should work on an existing vector instead of returning a new vector each time
	get rid of all fastExp code
	is there any need for the fudge term in the t- and F-test? 
		How large should the fudge term be?
	documentation of regularized logit boost
	review handling of rounding off errors towards end when splitting nodes (look in old code)
	smarter interrup handler
		The other threads also need to be stopped, test with Higgs
	clang code formatting
	what is the correct way of adding terms when calculating variable weights?
	variable weights as ArrayXd instead of vector<double>

possible optimizations:
	test PGO again
	test narrower type for strata
	float or double for outdata and weights?
	optimize case when all samples are used (usedSampleRation = 1.0, minSampleWeight = 0.0)
	alternative implementation of sortedUsedSamples
		select fastest implementation dynamically depending on sample count etc.
		maybe do this as a separate stump trainer class

========================================================================================================================

Eigen:
	read Eigen 3.4 docs
	report that
			ArrayXf a = {0, 4, 5};
		compiles

------------------------------------------------------------------------------------------------------------------------

Otto:
	run an explorative round with full dataset
		usedSampleRatio = [0.01, 0.02, .... 1]
		minNodeSize = [1,2,5,10, 20, , .... 10000]
	test regularized log loss with some gamma around 0.1?

	fit hyperparams jointly or separately for the different labels?
	try again with linloss, logloss and auc

	otto with frac = 0.001, assertion weights >= 0 fails  --- investigate

------------------------------------------------------------------------------------------------------------------------

review use of integer and floating point data types
	use int64_t as default integer type?

stump train strategy:
	current method has time complexity (in clock cycles)
		3 * sampleCount * usedVariableCount + 10 * usedSampleCount * usedVariableCount
	there is an alternative method with time complexity
		c * usedSampleCount * log2(usedSampleCount) * usedVariableCount + 10 * usedSampleCount * usedVariableCunt
	create a used sample list and sort it each time
	this might be faster when usedSampleCount is small i.e. when we do weight filtering and most weights are small
	use pdq-sort (https://github.com/orlp/pdqsort) when sorting

------------------------------------------------------------------------------------------------------------------------
	
Eigen issues:
	no select with two constants
	    StumpTrainerImpl(CRefXXf inData, RefXs strata)
			second argument should be CRefXs, but that leads to problems ...
	is BoostTrainer::trainAda_ slower with Eigen 3.4 than with Eigen 3.3.9?

========================================================================================================================

Notes:

/O2 = /Og /Oi /Ot /Oy /Ob2 /GF /Gy

/GL /O2 and /Ot make a big difference

/arch:AVX is faster than /arch:SSE and /arch:SSE2
/arch:AVX2 is not faster than /arch:AVX
the sppedup comes from BoostTrainer::trainAda_() (possibly the exp() call)

/fp:strict, /fp:pecise, /fp:fast: no clear difference, but there is no reason not to choose /fp:fast

splitmix is the fastest rng

FastBernoulliDistribution: uint64_t is much faster than double
  turning the class into a function does not increase speed

other MSVS 2019 settings:
    Tools > Options > Python > Conda: ..../conda.exe
    compiler flag:  /permissive-
    Run-time Library = Multi-threaded DLL (/MD) (for all configurations!)
    mixed debugging

numpy arrays are by default row major ("C storage order")
Eigen arrays are by default column major ("Fortran storage order")
