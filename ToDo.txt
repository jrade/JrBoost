
 major tasks:
	variable importance weights
	clean up Higgs and Otto
	BART
	histogram based stumps (would speed up Otto a lot)
	gradient boost

========================================================================

Trees:

	do next:

		review all code

		node buffers outside of splitfinders
			sortedSamplesByNodeBuffers
			unusedSampleBuffer

		no need for split finders in static storage

		sampleCountByStatus in static storage

		fast distribute samples for d = 0

		sampleStatus as size_t

		fix profiling
		fix iterationCount and slowBranchCount

		TreePredictor::Node -> TreeNode, replace #include "TreePredictor.h" by forward declarations


	profile and optimize
		distributeSamples() is a bit slow
			filter the samples first
		is sorted active samples pruning a good idea?? test this later?

	more testing

	parameters:
		decrease top variable count
		increase cycle count

	implement pruning
				
	implementation notes:
		where to init sums? or carry them over?

	later:
		usedVariables per level option?
		tree pruning
			keep the pruning completely outside StumpTrainer

	finally:
		ditch StumpTrainer?
			first make sure TreeTrainer with depth = 1 is as fast as StumpTrainer
		StumpOptions -> TreeOptions
		review friend declarations in class PROFILE

	are static thread_local buffers worth the trouble?

============================================================================================

predict overload that that takes a one-dim array and returns a double (use in QD Demo)

is there any need for the fudge term in the t- and F-test? 
	How large should the fudge term be?

================================================================================================

possible optimizations
	test PGO again
	test narrower type for strata
	float or double for outdata and weights?
	optimize case when all samples are used (usedSampleRation = 1.0, minSampleWeight = 0.0)
	alternative implementation of sortedUsedSamples
		select fastest implementation dynamically depending on sample count etc.
		maybe do this as a separate stump trainer class

documentation of regularized logit boost

new GitHub login method
	https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/

Eigen:
	read Eigen 3.4 docs
	report that
			ArrayXf a = {0, 4, 5};
		compiles
	pass Ref<const Array> by const ref?


should score > bestScore be replaced by something stricter?
	make init value of bestScore slightly larger?

========================================================================
	
Higgs:
	set up to run with the original kaggle files

	two modes:
		cv and submitt to kaggle server
		nested cv
			test 3 outer and 2 inner folds
		load function with random sampling for testing

	use weights when building predictor


	do some profiling with different numbers of train samples
		how long does it take to load file?
			transform to binary format?

Otto:
	run an explorative round with full dataset
		usedSampleRatio = [0.01, 0.02, .... 1]
		minNodeSize = [1,2,5,10, 20, , .... 10000]
	test regularized log loss with some gamma around 0.1?

	fit hyperparams jointly or separately for the different labels?
	try again with linloss, logloss and auc

	otto with frac = 0.001, assertion weights >= 0 fails  --- investigate

=====================================================================

U-test (with correct handling of ties)

gradient boost
	read xgb paper and Friedman to check that my understanding is correct

extended algorithms:
	first and second order boost
	alpha-beta boost with beta loss

review use of integer and floating point data types
	use int64_t as default integer type?

stump train strategy:
	current method has time complexity (in clock cycles)
		3 * sampleCount * usedVariableCount + 10 * usedSampleCount * usedVariableCount
	there is an alternative method with time complexity
		c * usedSampleCount * log2(usedSampleCount) * usedVariableCount + 10 * usedSampleCount * usedVariableCunt
	create a used sample list and sort it each time
	this might be faster when usedSampleCount is small i.e. when we do weight filtering and most weights are small
	use pdq-sort (https://github.com/orlp/pdqsort) when sorting

multiple inData and multiple variableCount (to handle feature engineering etc.)

----------------------------------------------------------------------

low prio:
	look in the old stub (or rather tree) builder code and see how I avoided rounding off errors towards the end
	L2-penalty (lambda) or L1-penalty (alpha)

	test accuracy of fast math
		1. improved fast math with smarter (x + 1) ^ (gamma-2)
		2. update the Gist with fastLog and fastPow
		3. plot min and max rel error of fastPow as a function of gamma
			let x range over 2 ** -n to 2 **n; seems the exact form of curve depends a little on on
			send a mail to Nic with the results

	better error messages when converting arguments to BoostTrainer::train

	profiling system that distinguishes between time in parallellized and non-parallellized code

	multinomial classification

======================================================================================
	
Eigen issues:
	no select with two constants
	    StumpTrainerImpl(CRefXXf inData, RefXs strata)
			second argument should be CRefXs, but that leads to problems ...
	is BoostTrainer::trainAda_ slower with Eigen 3.4 than with Eigen 3.3.9?

======================================================================================

Notes:

/O2 = /Og /Oi /Ot /Oy /Ob2 /GF /Gy

/GL /O2 and /Ot make a big difference

/arch:AVX is faster than /arch:SSE and /arch:SSE2
/arch:AVX2 is not faster than /arch:AVX
the sppedup comes from BoostTrainer::trainAda_() (possibly the exp() call)

/fp:strict, /fp:pecise, /fp:fast: no clear difference, but there is no reason not to choose /fp:fast

splitmix is the fastest rng

FastBernoulliDistribution: uint64_t is much faster than double
  turning the class into a function does not increase speed

other MSVS 2019 settings:
    Tools > Options > Python > Conda: ..../conda.exe
    compiler flag:  /permissive-
    Run-time Library = Multi-threaded DLL (/MD) (for all configurations!)
    mixed debugging

numpy arrays are by default row major ("C storage order")
Eigen arrays are by default column major ("Fortran storage order")
