
numpy arrays are by default row major ("C storage order")
Eigen arrays are by default column major ("Fortran storage order")

----------------------------------------------------------------------------------

main               20946   1.6%
  t-rank           22369   1.7%    4.0
  train boost     133276  10.0%   28.6
    train stump  1121972  84.3%   16.4
  predict          14867   1.1%   12.8
  OMP barrier       2773   0.2%
  dyn. memory      15129   1.1%  491.1
0:11:08


main               22566   1.6%
  t-rank           23557   1.7%    4.2
  train boost     118343   8.4%   29.6
    train stump   276772  19.6%
      T1          356664  25.2%    3.2
      T2          586490  41.5%   10.4
  predict          12930   0.9%   13.0
  OMP barrier       2383   0.2%
  dyn. memory      14285   1.0%  534.2
0:11:49

----------------------------------------------------------------------------------

predict that writes into existing array

then profile boost train again
	is it exp that takes time or is it something stupid?
		speed up exp with Agner Fog's VCLC++ vector class library?

profile with different instruction sets

use numpy instead of pandas in cv code
	pass sample list to t-test function instead of using the value 2 as a mask

profile on work computer with different numbers of threads
	include ccc in output again

stump trainer
	improve the profiling
	rerun old versions and compare
	any reason to reuse buffers, simpler thread safety if we do not

----------------------------------------------------------

stratifiedSubmask
	not hard to implement actually
	this shold take care of sumW_ = 0 problem
	add a minSampleWeight parameter and profile how many samples that fall below this
	also profile, seems a bit slow

========================================================

clean repo

push to GitHub

==============================================================


produce report
	first a simple one
    add a train and predict function similar to train and eval

gradient boost
	read xgb paper to check that my understanding is correct

trees
	pruning

--------------------------------------------------------------------

later:
	how to handle sumW_ == 0.0
		currently we return a stumppredictor that always predicts 0
		a better fix would be make sample selection among samples with weight != 0 (or > some threshold)
			this could be implemented as a stratified selection with weight 0 samples as a third stratum

	data members of boosters should be const
		can not iterate over const Eigen Ref object!!!!

	more memory efficient data in inner loop (use smalller integer types in arrays) - can save about 10%

	profile the parallellized part only and check how the performance scales with the number of processors

	allocate tree nodes with a memory pool

	test PGO

-----------------------------------------------------------

follow up alpha boost idea

----------------------------------------------------------------------

low prio:
	look in the old stub (or rather tree) builder code and see how I avoided rounding off errors towards the end
	faster uint64_t based Bernoulli distribution ??
	allow more than two strata in StumpPredictor?
	L2-penalty (lambda) or L1-penalty (alpha)
	multi-group

----------------------------------------------------------------------

PyBind11 issues:
	how translate custom C++ exceptions to standard Python exceptions
	no way of specifying noocnvert for property setters
	investigate abstract factory crash (JrBooster Crash)
		is the problem return values that are derived objects passed with unique_ptr to base class?
		test with the Miniconda that somes bundles with Visual Studio
	
Gerstmann issues:
	add move constructors to enable code such as
		xorshift rne((std::random_device()));
	seed function would be useful
	free functions (operator== and operator!=) should be inline
		or linker will complain if you include the header in multiple translation units
	should be standard compliant

Eigen issues:
	can not reset Ref objects
	no select with two constants
	    StumpTrainerImpl(CRefXXf inData, RefXs strata)
			second argument should be CRefXs, but that leads to problems ...

NumPy issues:
	inData[trainSamples, :] does not preserve Fortran (column major) order

------------------------------------------------------------------------

läs: https://romanpoya.medium.com/a-look-at-the-performance-of-expression-templates-in-c-eigen-vs-blaze-vs-fastor-vs-armadillo-vs-2474ed38d982

Notes:
	MSVS 2019:
		Tools > Options > Python > Conda: ..../conda.exe
		compiler flag:  /permissive-
		Run-time Library = Multi-threaded DLL (/MD) (for all configurations!)
		mixed debugging

	numpy: rowmajor
	eigen: colmajor

	https://docs.microsoft.com/en-us/visualstudio/python/working-with-c-cpp-python-in-visual-studio?view=vs-2019


----------------------------------------------------------------------------

https://stackoverflow.com/questions/29519222/how-to-transpose-a-16x16-matrix-using-simd-instructions
