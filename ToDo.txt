improved stratification in example programs
	need a strata numpy array, create at the same time as the one-hot encoded array
	first improve the logging: some of the item counts should be divided by the number of threads

Test with the Intel C++ compiler:
	Does it have better support for 128 threads?
	Does it have better support for SIMD vectorization?
	To do:
		1. report internal compiler error to
				https://community.intel.com/t5/Intel-C-Compiler/bd-p/c-compiler
		2. test how the compiler handles 128 threads
		3. improved vectorization (t-test, F-test, boost) ()
				first improve the logging: some of the item counts should be divided by the number of threads
				does this improve performance with many threads?
		4. report that vectors of overaligned data do  not compile
		5. check the alignment of buffers for such vectors
		6. cache line align TreeNodeTrainer and parallelize join splits

make another attempt at parallelizing outside the d-loop
	profile with Leukemia and 64 threads
	does this make the code too messy?

continue cleanup of TreeTrainerImpl

------------------------------------------------------------------------------------------------------------------------

major tasks:
	release 0.1 (reset file format version?)
	boosted forests
		maybe train with forestSize = 1, then build with a larger forestSize
	improved Higgs example (see "Higgs Notes.txt")
	tree regularization: L2 penalty (lambda), L1 penalty (alpha)
	BART
	improved Otto example
	gradient boost (Friedman and xgb papers)
		first and second order boost with any gamma
	histogram-based tree builder (would speed up Otto a lot)
	multinomial predictors
	documentation of regularized logit boost method

features to add:
	used variable subset by level option (would require saveMemory = True)
	strata that is distinct from out data (with possibly more than two strata)
	classifier compactification (remove unused variables, renumber (and reorder) the remaining variables)
	set seed to make the code deterministic (how to handle dynamic scheduling?)
	U-test (with correct handling of ties)
	multiple inData and multiple variable ounts (to handle feature engineering etc.)

minor things:
	test pruning again (also with abs limit)
	predict overload that takes a one-dim array and returns a double (use in QD Demo)
	is there any need for the fudge term in the t- and F-test? (How large should the fudge term be?)
	save and load:
		check that dataset does not have more than 2G variables
		get rid of uint32 nonsense
	compare performance (speed and accuracy) with xgboost
	clang code formatting
	
optimizations:
	make updateSampleStatus() code branch-free by introducing dummy nodes corresponding to status = 0 (unusued)
		maintain sorted lists of active samples to speed up this further
	compare performance with StumpTrainer (use Leukemia build and validate as a test case)
	data
		narrower type for strata
		float or double for outdata and weights?
		outData and weights interleaved in a single array
	PGO
	joinSplits_ could be parallelized, but this requires cache line alignment of TreeNodeBuilder
		this seems not to work with the Intel compiler

steps needed for the code to scale well with 128 threads:
	a preliminary test has shown that 128 threads might work well with 8 outer and 16 inner threads
	requires MSVC with openmp:/llvm (or the Intel compiler?)
	need better profiling:
		group the profiling numbers in 4 groups (unthread, outer, inner, synch)
		show the subtotal and percentage for each group
	SIMD optimize t-test, F-test, boost
	OMP optimize initSampleSttaus, updateSampleStatus
	fast jrboost.select(), jrboost.selectRows() and jrboost.selectColumns()

------------------------------------------------------------------------------------------------------------------------

Otto:
	run an explorative round with full dataset
		usedSampleRatio = [0.01, 0.02, .... 1]
		minNodeSize = [1,2,5,10, 20, , .... 10000]
	test regularized log loss with some gamma around 0.1?
	fit hyperparams jointly or separately for the different labels?
	try again with linloss, logloss and auc
	otto with frac = 0.001, assertion weights >= 0 fails  --- investigate

Eigen issues:
	read Eigen 3.4 docs
	report that
			ArrayXf a = {0, 4, 5};
		compiles but gives unexpected result
	no select with two constants
	    StumpTrainerImpl(CRefXXf inData, RefXs strata)
			second argument should be CRefXs, but that leads to problems ...
	is BoostTrainer::trainAda_ slower with Eigen 3.4 than with Eigen 3.3.9?

------------------------------------------------------------------------------------------------------------------------

Notes:

The Visual Studio project used the environment variables EIGEN_DIR, PYTHON_DIR and PYBIND11_DIR
to find third party header and library files

/O2 = /Og /Oi /Ot /Oy /Ob2 /GF /Gy

/GL /O2 and /Ot make a big difference

/arch:AVX is faster than /arch:SSE and /arch:SSE2
/arch:AVX2 is not faster than /arch:AVX

/fp:strict, /fp:pecise, /fp:fast: no clear difference, but there is no reason not to choose /fp:fast

splitmix is the fastest rng

FastBernoulliDistribution: uint64_t is much faster than double
  turning the class into a function does not increase speed

other MSVS 2019 settings:
    Tools > Options > Python > Conda: ..../conda.exe
    compiler flag:  /permissive-
    Run-time Library = Multi-threaded DLL (/MD) (for all configurations!)
    mixed debugging

numpy arrays are by default row major ("C storage order")
Eigen arrays are by default column major ("Fortran storage order")
