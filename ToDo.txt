
numpy arrays are by default row major ("C storage order")
Eigen arrays are by default column major ("Fortran storage order")

----------------------------------------------------------------------------------

main                 20859   1.7%
  t-rank             23291   1.9%    4.1
  train boost        94485   7.8%   21.3
    train stump    1014039  83.3%
      validate       38325   3.1%    8.6
  predict             8653   0.7%
  OMP barrier         2343   0.2%
  dyn. memory        15642   1.3%  531.2

0:10:11

----------------------------------------------------------------------------------

ADA boost: move f0 calculation to constructor
	validate Fy.sum = 0 before first iteration

put together faster test case for profiling - maybe just nested = False?

profile with different instruction sets, different float flags, other settings?

profile on work computer with different numbers of threads

stump trainer
	huge performance loss by using data members instead of local variables??
	improve the profilings
	rerun old versions and compare
	any reason to reuse buffers, simpler thread safety if we do not

what type to use for out data matrix in python and in C interface??

----------------------------------------------------------

stratifiedSubmask
	not hard to implement actually
	this shold take care of sumW_ = 0 problem
	add a minSampleWeight parameter and profile how many samples that fall below this
	also profile, seems a bit slow

========================================================

clean repo

push to GitHub

==============================================================

produce report
	first a simple one
    add a train and predict function similar to train and eval

gradient boost
	read xgb paper to check that my understanding is correct

trees
	pruning

--------------------------------------------------------------------

later:
	how to handle sumW_ == 0.0
		currently we return a stumppredictor that always predicts 0
		a better fix would be make sample selection among samples with weight != 0 (or > some threshold)
			this could be implemented as a stratified selection with weight 0 samples as a third stratum

	data members of boosters should be const
		can not iterate over const Eigen Ref object!!!!

	more memory efficient data in inner loop (use smalller integer types in arrays) - can save about 10%

	profile the parallellized part only and check how the performance scales with the number of processors

	allocate tree nodes with a memory pool

	test PGO

-----------------------------------------------------------

follow up alpha boost idea

----------------------------------------------------------------------

low prio:
	look in the old stub (or rather tree) builder code and see how I avoided rounding off errors towards the end
	faster uint64_t based Bernoulli distribution ??
	allow more than two strata in StumpPredictor?
	L2-penalty (lambda) or L1-penalty (alpha)
	multi-group

----------------------------------------------------------------------

PyBind11 issues:
	how translate custom C++ exceptions to standard Python exceptions
	no way of specifying noocnvert for property setters
	investigate abstract factory crash (JrBooster Crash)
		is the problem return values that are derived objects passed with unique_ptr to base class?
		test with the Miniconda that somes bundles with Visual Studio
	
Gerstmann issues:
	add move constructors to enable code such as
		xorshift rne((std::random_device()));
	seed function would be useful
	free functions (operator== and operator!=) should be inline
		or linker will complain if you include the header in multiple translation units
	should be standard compliant

Eigen issues:
	can not reset Ref objects
	no select with two constants
	    StumpTrainerImpl(CRefXXf inData, RefXs strata)
			second argument should be CRefXs, but that leads to problems ...

NumPy issues:
	inData[trainSamples, :] does not preserve Fortran (column major) order

------------------------------------------------------------------------

läs: https://romanpoya.medium.com/a-look-at-the-performance-of-expression-templates-in-c-eigen-vs-blaze-vs-fastor-vs-armadillo-vs-2474ed38d982

Notes:
	MSVS 2019:
		Tools > Options > Python > Conda: ..../conda.exe
		compiler flag:  /permissive-
		Run-time Library = Multi-threaded DLL (/MD) (for all configurations!)
		mixed debugging

	numpy: rowmajor
	eigen: colmajor

	https://docs.microsoft.com/en-us/visualstudio/python/working-with-c-cpp-python-in-visual-studio?view=vs-2019


----------------------------------------------------------------------------

https://stackoverflow.com/questions/29519222/how-to-transpose-a-16x16-matrix-using-simd-instructions
