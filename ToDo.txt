



main                     19046   1.7%
  t-rank                 22056   2.0%    3.9
  train boost            79284   7.1%   21.3
    train stump          30225   2.7%    8.2
      used samples       45953   4.1%   12.1
      used variables     15312   1.4%   12.5
      sums               16161   1.5%    4.6
      sorted used s.    300411  27.0%    3.2
      best split        564124  50.6%   10.7
  predict                 7152   0.6%
  OMP barrier             1712   0.2%
  dyn. memory            12385   1.1%  637.6

zero calibration: 82
profiling overhead: 12.0%
slow branch: 1.4%

0:10:26

=====================================================================

Ti:
	make consistent use of SampleIndex type
	profile with different values

	profile with different indata, outdata and sample index types
		make consistent use of SampleIndex type
		turn all three into typedesf?
		other sample index type can save 10%?

O:
	profile on work computer with different numbers of threads
		how does it scale?

	minSampleWeight and stratifiedRandomSubmask
		not hard to implement actually
		this shold take care of sumW_ = 0 problem
		add a minSampleWeight parameter and profile how many samples that fall below this
		play around with this stuff

To - S:
	clean repo
		test with CERN boson data instead

	push to GitHub

=====================================================================

Pandas free Python code

sampleIndex_t typedef
	select Bernoulli implementation based on this type

what type to use for out data matrix in python and in C interface??

produce report
	first a simple one
    add a train and predict function similar to train and eval

-----------------------------------------------------------------------

gradient boost
	read xgb paper to check that my understanding is correct

trees
	pruning
	allocate nodes with a memory pool

data members of boosters should be const
	can not iterate over const Eigen Ref object!!!!

test PGO

----------------------------------------------------------------------

low prio:
	look in the old stub (or rather tree) builder code and see how I avoided rounding off errors towards the end
	allow more than two strata in StumpPredictor?
	L2-penalty (lambda) or L1-penalty (alpha)
	multi-group
	follow up alpha boost idea

----------------------------------------------------------------------

PyBind11 issues:
	how translate custom C++ exceptions to standard Python exceptions
	no way of specifying noocnvert for property setters
	investigate abstract factory crash (JrBooster Crash)
		is the problem return values that are derived objects passed with unique_ptr to base class?
		test with the Miniconda that somes bundles with Visual Studio
	
Gerstmann issues:
	add move constructors to enable code such as
		xorshift rne((std::random_device()));
	seed function would be useful
	free functions (operator== and operator!=) should be inline
		or linker will complain if you include the header in multiple translation units
	should be standard compliant

Eigen issues:
	can not reset Ref objects
	no select with two constants
	    StumpTrainerImpl(CRefXXf inData, RefXs strata)
			second argument should be CRefXs, but that leads to problems ...

NumPy issues:
	inData[trainSamples, :] does not preserve Fortran (column major) order

------------------------------------------------------------------------

take a look at std::span, std::view, std::mdview, ranges etc in C++20

