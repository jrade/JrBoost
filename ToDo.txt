new GitHub login method
	https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/

========================================================================================================================

TreeBuilderImpl:

	general code review and cleanup
		replace sampleCountByStatus_ by orderedSampleIndex_
			index with 0 = first node (no need to index any unused samples)
		mark all static thread local members with the prefix tl
			avoid accessing them directly
		if we allowed depth = 0 (and why wouldn't we?), then root would not get properly initialized

	do some more profiling

	The current implementation of TreeBuilderImpl is cache memory efficient
		Put together a modified CPU friendly implementation
			Borrow from TreeTrainerImplD
		Combine them in a single train function?
		Control which one to use with a flag
	
	Profiling cases (both on notebook and stationary PC)
		Leukemia build-and-validate
		higgs.py and higgs_quick.py

	Discard TreeTrainerImplB, TreeTrainerImplC, TreeTrainerImplD and NodeBuilder
		Keep StumpTrainerImpl for the record
		Remove obsolete friend declarations

	Clean up profiling

	Later:
		test pruning again
		low/high memory hybrid scheme for TreeBuilderImpl?

	Minor things:
		Trick to reduce rounding off errors towards the end
			calculate right sums as total - left instead of doing it incrementally
			then we should have right sum == 0.0 at the end (assert this?)
		micro optimizationss
			more branch-free code
		more efficient storage of usedSortedSamples, orderedSamples_ etc? (by variable index instead of by variable)		
			would not work with a (yet to be implemented) select variables by level mode
		code simplification:
			are static thread_local buffers worth the trouble?

------------------------------------------------------------------------------------------------------------------------

Higgs:

	feature engineering
		read paper appendix A, then appendix B
		look at winning (and other) submissions

	target loss functions (for fitting hyper parameters):
		AUC:      3.7372 -> 3.7403
		AMS:      3.7340 -> 3.7342
		ll(1e-3): 3.7156 -> 3.7073
	
	more robust AMS cutoff fitting (testing every possible cutoff may lead to overfitting, apply some smoothing?)
	also: test simple cutoff again
	population optimization parameters (generator approach)
	repetition count

	minGain feature
	forward and backward pruning
	drop useless variables?

	cross-validation for fitting hyper parameters and AMS cutoff
		only use the data files train.csv and test.csv from Kaggle competition
		trainer that works with sample subset

	look at final version of my Kaggle code
	look at winning submissions, paper, code at https://github.com/melisgl/higgsml
	look at other publicly available submissions
		
	do some profiling
		how does it scale with number of cores (using the full dataset)
		what takes so much time at the end?

	compare with the xgbost higgs example:
		speed, accuracy?

	how does higgs.py find jrboost when importing it? (this ís a bit of a mystery)

------------------------------------------------------------------------------------------------------------------------

major tasks:
	other parallellization schemes
	improved Otto example
	gradient boost (Friedman and xgb papers)
		first and second order boost with any gamma
	BART
	histogram-based tree builder (would speed up Otto a lot)
	multinomial predictors

features to add:
	classifier compactification (remove unused variables, renumber (and reorder) the remaining variables)
	tree regularization: L2 penalty (lambda), L1 penalty (alpha)
	used variable subset by level option (may be expensive)
	predict overload that takes a one-dim array and returns a double (use in QD Demo)
	multiple inData and multiple variable counts (to handle feature engineering etc.)
	set seed (to make the training process deterministic)
	U-test (with correct handling of ties)

minor things:
	Rename the jrboost.py project Python, move it up one step in the solution explorer hierarchy
	decrease default gamma (in log loss) from 0.1 to 0.001?
	Predictor::_predict should work on an existing vector instead of returning a new vector each time
	get rid of all fastExp code
	is there any need for the fudge term in the t- and F-test? 
		How large should the fudge term be?
	documentation of regularized logit boost
	review handling of rounding off errors towards end when splitting nodes (look in old code)
	smarter interrup handler
		The other threads also need to be stopped, test with Higgs
	clang code formatting
	what is the correct way of adding terms when calculating variable weights?
	variable weights as ArrayXd instead of vector<double>

possible optimizations:
	test PGO again
	test narrower type for strata
	float or double for outdata and weights?
	optimize case when all samples are used (usedSampleRation = 1.0, minSampleWeight = 0.0)
	alternative implementation of sortedUsedSamples
		select fastest implementation dynamically depending on sample count etc.
		maybe do this as a separate stump trainer class

========================================================================================================================

Eigen:
	read Eigen 3.4 docs
	report that
			ArrayXf a = {0, 4, 5};
		compiles

------------------------------------------------------------------------------------------------------------------------

Otto:
	run an explorative round with full dataset
		usedSampleRatio = [0.01, 0.02, .... 1]
		minNodeSize = [1,2,5,10, 20, , .... 10000]
	test regularized log loss with some gamma around 0.1?

	fit hyperparams jointly or separately for the different labels?
	try again with linloss, logloss and auc

	otto with frac = 0.001, assertion weights >= 0 fails  --- investigate

------------------------------------------------------------------------------------------------------------------------

review use of integer and floating point data types
	use int64_t as default integer type?

stump train strategy:
	current method has time complexity (in clock cycles)
		3 * sampleCount * usedVariableCount + 10 * usedSampleCount * usedVariableCount
	there is an alternative method with time complexity
		c * usedSampleCount * log2(usedSampleCount) * usedVariableCount + 10 * usedSampleCount * usedVariableCunt
	create a used sample list and sort it each time
	this might be faster when usedSampleCount is small i.e. when we do weight filtering and most weights are small
	use pdq-sort (https://github.com/orlp/pdqsort) when sorting

------------------------------------------------------------------------------------------------------------------------
	
Eigen issues:
	no select with two constants
	    StumpTrainerImpl(CRefXXf inData, RefXs strata)
			second argument should be CRefXs, but that leads to problems ...
	is BoostTrainer::trainAda_ slower with Eigen 3.4 than with Eigen 3.3.9?

========================================================================================================================

Notes:

/O2 = /Og /Oi /Ot /Oy /Ob2 /GF /Gy

/GL /O2 and /Ot make a big difference

/arch:AVX is faster than /arch:SSE and /arch:SSE2
/arch:AVX2 is not faster than /arch:AVX
the sppedup comes from BoostTrainer::trainAda_() (possibly the exp() call)

/fp:strict, /fp:pecise, /fp:fast: no clear difference, but there is no reason not to choose /fp:fast

splitmix is the fastest rng

FastBernoulliDistribution: uint64_t is much faster than double
  turning the class into a function does not increase speed

other MSVS 2019 settings:
    Tools > Options > Python > Conda: ..../conda.exe
    compiler flag:  /permissive-
    Run-time Library = Multi-threaded DLL (/MD) (for all configurations!)
    mixed debugging

numpy arrays are by default row major ("C storage order")
Eigen arrays are by default column major ("Fortran storage order")
