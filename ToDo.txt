
main                     18749   1.6%
  t-rank                 22618   1.9%    4.0
  train boost            74215   6.2%   20.3
    train stump          13087   1.1%
      validate           32106   2.7%    9.1
      used samples       45815   3.8%   12.8
      used variables     15467   1.3%   13.5
      sums               20456   1.7%    6.0
      sorted used s.    341544  28.6%    3.8
      best split        589351  49.4%   11.6
  predict                 7149   0.6%
  OMP barrier             1872   0.2%
  dyn. memory            10793   0.9%  633.3

zero calibration: 104
profiling overhead: 14.6%
slow branch: 1.5%

0:11:27


Ti:
	no point in reusing buffers
		verify this again with the improved profiling
		simplify the code! get rid of the by_thread and shared classes!!
		how to initialize the thread local random number engines?

O:
	profile with different indata, outdata and sample index types
		make consistent use of SampleIndex type
		turn all three into typedesf?
		other sample index type can save 10%?

	profile on work computer with different numbers of threads
		how does it scale?

To - S:
	clean repo
		test with CERN boson data instead

	push to GitHub

=====================================================================

play around with for instance with minNodeSize and minNodeWeight

Pandas free Python code

sampleIndex_t typedef
	select Bernoulli implementation based on this type

minSampleWeight and stratifiedRandomSubmask
	not hard to implement actually
	this shold take care of sumW_ = 0 problem
	add a minSampleWeight parameter and profile how many samples that fall below this

what type to use for out data matrix in python and in C interface??

produce report
	first a simple one
    add a train and predict function similar to train and eval

gradient boost
	read xgb paper to check that my understanding is correct

trees
	pruning
	allocate nodes with a memory pool

data members of boosters should be const
	can not iterate over const Eigen Ref object!!!!

test PGO

----------------------------------------------------------------------

low prio:
	look in the old stub (or rather tree) builder code and see how I avoided rounding off errors towards the end
	allow more than two strata in StumpPredictor?
	L2-penalty (lambda) or L1-penalty (alpha)
	multi-group
	follow up alpha boost idea

----------------------------------------------------------------------

PyBind11 issues:
	how translate custom C++ exceptions to standard Python exceptions
	no way of specifying noocnvert for property setters
	investigate abstract factory crash (JrBooster Crash)
		is the problem return values that are derived objects passed with unique_ptr to base class?
		test with the Miniconda that somes bundles with Visual Studio
	
Gerstmann issues:
	add move constructors to enable code such as
		xorshift rne((std::random_device()));
	seed function would be useful
	free functions (operator== and operator!=) should be inline
		or linker will complain if you include the header in multiple translation units
	should be standard compliant

Eigen issues:
	can not reset Ref objects
	no select with two constants
	    StumpTrainerImpl(CRefXXf inData, RefXs strata)
			second argument should be CRefXs, but that leads to problems ...

NumPy issues:
	inData[trainSamples, :] does not preserve Fortran (column major) order

------------------------------------------------------------------------

take a look at std::span, std::view, std::mdview, ranges etc in C++20

